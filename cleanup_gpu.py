#!/usr/bin/env python3

import torch
import gc
import time

print("üßπ Clearing GPU memory...")
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    print(f"‚úÖ GPU memory cleared. Reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f}GB")
else:
    print("‚ö†Ô∏è  CUDA not available")

gc.collect()
time.sleep(1)
print("‚úÖ Done")
